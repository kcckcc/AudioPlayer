{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYSD7UEITD2p5xvckdhN/E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcckcc/AudioPlayer/blob/main/Stella_Bible_Study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Find the .mp3 file under recording_path not matching _part?.mp3\n",
        "\n",
        "import os\n",
        "import re\n",
        "\n",
        "def find_mp3_file(recording_path):\n",
        "  for filename in os.listdir(recording_path):\n",
        "    if filename.endswith(\".mp3\") and not re.match(r\".*_part\\d\\.mp3\", filename):\n",
        "      return os.path.join(recording_path, filename)\n",
        "  return None\n",
        "\n",
        "\n",
        "recording_path = \"D:\\\\React\\\\biblestudy\\\\public\\\\book\\\\Proverbs (2015)\\\\2015-05-02\"\n",
        "mp3_file = find_mp3_file(recording_path)\n",
        "if mp3_file:\n",
        "  print(f\"Found MP3 file: {mp3_file}\")\n",
        "else:\n",
        "  print(\"No matching MP3 file found.\")\n",
        "\n",
        "!D:\\React\\biblestudy\\DownloadRecording\\SplitAudio\\bin\\Release\\net8.0\\SplitAUdio.exe mp3_file"
      ],
      "metadata": {
        "id": "SPe0bEOdqMTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!D:\\React\\biblestudy\\DownloadRecording\\SplitAudio\\bin\\Release\\net8.0\\SplitAUdio.exe mp3_file"
      ],
      "metadata": {
        "id": "PaeS0wKqfBB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Iterate the file in current folder and store the name end with \"_part?.mp3\" in an array and sort with ascending order\n",
        "\n",
        "import os\n",
        "import re\n",
        "\n",
        "def get_sorted_mp3_files(directory):\n",
        "  mp3_files = []\n",
        "  try:\n",
        "    for filename in os.listdir(directory):\n",
        "      if re.match(r\".*_part\\d+\\.mp3\", filename):  # Use regex for more flexible matching\n",
        "        mp3_files.append(filename)\n",
        "    mp3_files.sort() # Sort the files alphabetically\n",
        "    return mp3_files\n",
        "  except OSError as e:\n",
        "    print(f\"Error accessing directory: {e}\")\n",
        "    return []\n",
        "\n",
        "\n",
        "mp3_part_files = get_sorted_mp3_files(recording_path)\n",
        "\n",
        "if mp3_part_files:\n",
        "  print(\"MP3 Part files:\")\n",
        "  for file in mp3_part_files:\n",
        "    print(file)\n",
        "else:\n",
        "  print(\"No matching MP3 files found in the directory or an error occurred.\")\n",
        "\n",
        "# Get book and verses name\n",
        "file_name = mp3_part_files[0]\n",
        "\n",
        "idx = file_name.rfind('_part')  # Find the index of the first '.' (file extension)\n",
        "if idx != -1:\n",
        "    recording_name = file_name[:idx]\n",
        "    idx = recording_name.rfind('_')\n",
        "    if idx != -1:\n",
        "        book_name = recording_name[:idx].replace('_', ' ')\n",
        "        verses = recording_name[idx + 1:].replace('^', ':')\n",
        "        print(f\"Book Name: {book_name}\")\n",
        "        print(f\"Verses: {verses}\")\n",
        "    else:\n",
        "        print(\"'_' not found in filename\")\n",
        "else:\n",
        "    print(\"'.' not found in filename\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ngNO_mG4kD7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Define a function that write response_text to an output file and upload to client\n",
        "\n",
        "import pathlib\n",
        "\n",
        "def write_and_upload(response_text, output_filename):\n",
        "  text_bytes = response_text.encode('utf-8')\n",
        "  text_path = pathlib.Path(output_filename)\n",
        "  text_path.write_bytes(text_bytes)\n",
        "  file_upload = client.files.upload(file=text_path)\n"
      ],
      "metadata": {
        "id": "3hOaw1pNmaEZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U -q 'google-genai>=1.4.0' # 1.4.0 is needed for chat history\n",
        "\n",
        "from google.colab import userdata\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "client = genai.Client(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "Sp7xDMooEeTz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-2.5-pro-exp-03-25\" # @param [\"gemini-2.0-flash-lite\",\"gemini-2.0-flash\",\"gemini-2.5-flash-preview-04-17\",\"gemini-2.5-pro-exp-03-25\"] {\"allow-input\":true, isTemplate: true}"
      ],
      "metadata": {
        "id": "FEes8FTGEiv1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "system_instruction = \"\"\"\n",
        "  You are an expert in language translation and a bible scholar.\n",
        "\"\"\"\n",
        "\n",
        "chat_config = types.GenerateContentConfig(\n",
        "    system_instruction=system_instruction,\n",
        ")\n",
        "\n",
        "chat = client.chats.create(\n",
        "    model=MODEL_ID,\n",
        "    config=chat_config,\n",
        ")"
      ],
      "metadata": {
        "id": "8bl0OAHB74kA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp3_part_files = [\"Proverbs_10^7-14_part1.mp3\", \"Proverbs_10^7-14_part2.mp3\"]\n",
        "\n",
        "for mp3_part_file in mp3_part_files:\n",
        "  print (mp3_part_file)\n",
        ""
      ],
      "metadata": {
        "id": "l-0UoOsBshiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Invoke client.models.generate_context and check for error such as daily limit exceed\n",
        "\n",
        "from google.api_core import exceptions\n",
        "\n",
        "def generate_context_with_error_handling(client, model_id, messages):\n",
        "    try:\n",
        "        response = client.models.generate_context(\n",
        "            model=model_id,\n",
        "            context=messages\n",
        "        )\n",
        "        return response\n",
        "    except exceptions.PermissionDenied as e:\n",
        "        print(f\"Permission denied: {e}\")\n",
        "        if \"daily limit\" in str(e).lower():\n",
        "            print(\"Daily limit exceeded for this model.\")\n",
        "        return None\n",
        "    except exceptions.ResourceExhausted as e:\n",
        "        print(f\"Resource exhausted: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "qAq1KoYdvYv9"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def PromptModel(prompt, input_data):\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        response = client.models.generate_content(\n",
        "        model=MODEL_ID,\n",
        "          contents=[\n",
        "            input_data,\n",
        "            prompt,\n",
        "          ],\n",
        "        )\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        minutes = int(elapsed_time // 60)\n",
        "        seconds = int(elapsed_time % 60)\n",
        "        print(f\"Response took {minutes} minutes and {seconds} seconds to complete.\")\n",
        "        return response.text\n",
        "    except exceptions.PermissionDenied as e:\n",
        "        print(f\"Permission denied: {e}\")\n",
        "        if \"daily limit\" in str(e).lower():\n",
        "            print(\"Daily limit exceeded for this model.\")\n",
        "        return \"limit_error\"\n",
        "    except exceptions.ResourceExhausted as e:\n",
        "        print(f\"Resource exhausted: {e}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def PromptModelWithRetry(prompt, input_data):\n",
        "  retry_count = 0\n",
        "  response = None\n",
        "  while response is None and retry_count < 30:\n",
        "    response = PromptModel(prompt, input_data)\n",
        "    if response == \"limit_error\":\n",
        "      print(\"Daily limit exceeded for this model.\")\n",
        "      response = None\n",
        "      break\n",
        "    elif response is not None:\n",
        "        print(f\"response size {len(response)}.\")\n",
        "        return response\n",
        "    else:\n",
        "      print(f\"Retrying {mp3_part_file}... Attempt {retry_count + 1}/30\")\n",
        "      time.sleep(60)  # Wait for 1 minute\n",
        "      retry_count += 1\n",
        "\n",
        "  return response\n"
      ],
      "metadata": {
        "id": "LZ4W-RmNGLHx"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# prompt:  For each mp3_part_files, call ConvertToTranscript, stop if response is \"limit_error\",  wait for 1 minute and retry if response is None for 30 times, otherwise append response to cantonese_text\n",
        "\n",
        "import time\n",
        "prompt = \"Translate this Cantonese bible study \" + book_name + \" \" + verses + \" teaching class audio to Chinese Traditional character. Ignore laughing sound. After that, remove timeline and group message into paragraphs. Do not summarize the message. She mention Saddleback Church a lot.\"\n",
        "\n",
        "cantonese_text = \"\"\n",
        "for mp3_part_file in mp3_part_files:\n",
        "  print(\"Try  \" + mp3_part_file)\n",
        "  # response = ConvertToTranscript(os.path.join(recording_path, mp3_part_file))\n",
        "  input_data = client.files.upload(file=mp3_part_file)\n",
        "  response = PromptModelWithRetry(prompt, input_data)\n",
        "  if response is not None:\n",
        "    cantonese_text += response\n",
        "\n",
        "if cantonese_text:\n",
        "  write_and_upload(cantonese_text, 'cantonese.txt')\n",
        "else:\n",
        "  print(\"No text to write.\")\n",
        "\n",
        "write_and_upload(client, cantonese_text, 'cantonese.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkI7mzFnw6W7",
        "outputId": "79e59d44-634a-456e-de76-ba55a58f67ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Try  Proverbs_10^7-14_part1.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Translate this to Simplified Chinese characters. Add translation for any English in Simplified Chinese characters next to it. Keep the paragraph format and add a line spacing between paragraphs.\"\n",
        "\n",
        "simplified_text = PromptModelWithRetry(prompt, cantonese_text)\n",
        "write_and_upload( response.text, 'simplified.txt')"
      ],
      "metadata": {
        "id": "hWU4X1nUPia0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Translate to English with all Chinese words inside the translation removed. Keep the paragraph format and add a line spacing between paragraphs. Also fix grammatical errors such as repeated words.\"\n",
        "\n",
        "english_text = PromptModelWithRetry(prompt, cantonese_text)\n",
        "write_and_upload( response.text, 'english.txt')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7IFRz2FjMJHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Summarize the teaching in Cantonese.\"\n",
        "\n",
        "cantonese_summary = PromptModelWithRetry(prompt, cantonese_text)\n",
        "write_and_upload( cantonese_summary, 'cantonese_summary.txt')"
      ],
      "metadata": {
        "id": "YFADeC45_PEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Translate this to Simplified Chinese characters.  Keep the paragraph format and add a line spacing between paragraphs.\"\n",
        "\n",
        "simplified_summary = PromptModelWithRetry(prompt, cantonese_summary)\n",
        "write_and_upload( simplified_summary, 'simplified_summary.txt')"
      ],
      "metadata": {
        "id": "UO9He-JEYsqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Translate this to English with all Chinese words inside the translation removed. Keep the paragraph format and add a line spacing between paragraphs.\"\n",
        "english_summary = PromptModelWithRetry(prompt, cantonese_summary)\n",
        "write_and_upload( english_summary, 'english_summary.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLudETZgYbli",
        "outputId": "f7ee7c29-921b-448f-cc92-b52f12bf3b90"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cache_tokens_details=None cached_content_token_count=None candidates_token_count=5041 candidates_tokens_details=None prompt_token_count=1283 prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=1283)] thoughts_token_count=3639 tool_use_prompt_token_count=None tool_use_prompt_tokens_details=None total_token_count=6324 traffic_type=None\n"
          ]
        }
      ]
    }
  ]
}